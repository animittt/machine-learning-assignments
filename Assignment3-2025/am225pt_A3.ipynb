{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "**name:** Ani Mitoyan\n",
    "\n",
    "**email:** am225pt@student.lnu.se\n",
    "\n",
    "In this Assignment, you will use Python to handle several exercises related the last 4 topics of the course.\n",
    "All exercises are individual. \n",
    "We expect you to submit a Jupyter Notebook (i.e., pre-organized and provided through Moodle). \n",
    "Your submission should include all the datasets and files we need to run your programs (we will run your notebook). \n",
    "When grading your assignments, we will, in addition to functionality, also take into account code quality. \n",
    "We expect well-structured and efficient solutions.\n",
    "\n",
    "## Lecture 6 - Decision Trees and Ensembles\n",
    "\n",
    "**Dataset:** Bank Marketing Dataset (UCI)\n",
    "\n",
    "**Variables description:** Check the bank-aditional-names.txt file\n",
    "\n",
    "**Task Description:** Predict whether a client will subscribe to a term deposit (y column) based on marketing data.\n",
    "\n",
    "### Task 1 (mandatory): Data Exploration and Preprocessing\n",
    "\n",
    "Load and clean the dataset (bank-additional-full.csv). Encode categorical features. Split the dataset into training and testing sets.\n",
    "\n",
    "**Plot:** Show class distribution (e.g., a print) of the target variable and a bar chart of the most frequent categorical values.\n",
    "\n",
    "**Discuss:** Is the dataset imbalanced? Which features stand out?\n",
    "\n",
    "--- Your answer here ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (Mandatory): Train a decision tree using scikit-learn.\n",
    "\n",
    "Use max depth = 4 for initial interpretability. Visualize the tree using plot_tree().\n",
    "\n",
    "**Discuss:** Which features are used at the top levels of the tree? Are they intuitive? \n",
    "\n",
    "--- Your answer here ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (mandatory): Evaluate Performance and Overfitting\n",
    "Train the same tree with increasing depths (e.g., 2 to 10). Evaluate on both training and test sets using accuracy and F1 score. Plot Accuracy vs. depth and F1 vs. depth.\n",
    "\n",
    "**Discuss:** Is there overfitting? Where does performance peak?\n",
    "\n",
    "--- Your answer here ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (Mandatory): Train and Compare Ensembles\n",
    "Train a Random Forest and a Gradient Boosting model.\n",
    "Tune hyperparameters using grid search (e.g., max_depth, n_estimators).\n",
    "Do a plot comparing the ROC curves of the three models (Tree, RF, GB).\n",
    "\n",
    "**Discuss:** Which model performs best and why?\n",
    "\n",
    "---- Your answers here ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (Non-Mandatory): Feature Importance Analysis\n",
    "\n",
    "Extract and plot feature importances for the ensemble models.\n",
    "\n",
    "Plot the top 10 features by importance (bar chart).\n",
    "\n",
    "**Discuss:** Are these the same features that dominated the decision tree?\n",
    "\n",
    "---- Your answers here ----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (Non-Mandatory): Test Model Robustness to Noisy Features\n",
    "\n",
    "Add synthetic noise features to the dataset. \n",
    "Generate 5–10 random columns with values sampled from a uniform or normal distribution.\n",
    "Concatenate them with the original feature set.\n",
    "Retrain your Random Forest and Gradient Boosting with the noisy features included.\n",
    "Evaluate their performance on the test set.\n",
    "\n",
    "Create a Bar plot comparing test set accuracy or F1 score before adding noise and after adding noise. \n",
    "\n",
    "**Discuss:** Did model performance degrade? Why or why not?\n",
    "\n",
    "What does this tell you about the model’s ability to ignore irrelevant features?\n",
    "\n",
    "Would feature selection or regularization help in this case?\n",
    "\n",
    "--- Your answer here --- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 7 - Kernels, Maximal Margin Classifiers\n",
    "\n",
    "### Task 1 (Mandatory): Data Exploration and Preprocessing\n",
    "\n",
    "Load the dataset using sklearn.datasets.load_breast_cancer().\n",
    "\n",
    "Standardize the features using StandardScaler.\n",
    "Use pairplot or PCA to project to 2D and show class separation.\n",
    "\n",
    "**Discuss:** Do the two classes appear linearly separable?\n",
    " \n",
    "--- Your answer here --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (Mandatory): Train Linear and RBF SVMs\n",
    "\n",
    "Train two SVM classifiers: one with a linear kernel and one with an RBF kernel.\n",
    "\n",
    "Use a fixed C=1.0, and for RBF, use default gamma='scale'.\n",
    "\n",
    "Plot the confusion matrices or classification reports for both models.\n",
    "\n",
    "**Discuss:** Which kernel performed better? Why might that be?\n",
    "\n",
    "--- Your answer here --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (Mandatory): Hyperparameter Tuning\n",
    "\n",
    "Use grid search with cross-validation to find optimal values of C and gamma for the RBF kernel.\n",
    "\n",
    "Plot a heatmap of validation accuracy or F1 score for the grid.\n",
    "\n",
    "**Discuss:** What combination of hyperparameters gave the best results?\n",
    "\n",
    "--- Your answer here --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (non-mandatory): Investigate the Effect of the Regularization Parameter C\n",
    "\n",
    "Train RBF SVM models for a wide range of C values (e.g., 0.001, 0.01, 0.1, 1, 10, 100), keeping gamma fixed.\n",
    "\n",
    "For each model, record training and test accuracy or F1 score.\n",
    "\n",
    "Plot the training and test scores vs. C (line plot).\n",
    "\n",
    "**Discuss:**\n",
    "\n",
    "- What happens when C is very small or very large?\n",
    "\n",
    "- What does this tell you about the role of C in the SVM objective?\n",
    "\n",
    "--- Your answer here --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (non-mandatory): Compare SVM with Logistic Regression\n",
    "\n",
    "Train a logistic regression model on the same (standardized) data.\n",
    "\n",
    "Compare its performance with your best-performing SVM.\n",
    "\n",
    "Plot, side-by-side bar plot of accuracy, precision, recall, and F1 score for both models.\n",
    "\n",
    "**Discuss:**\n",
    "\n",
    "- Which model performed better overall?\n",
    "\n",
    "- Were there significant differences in false positives or false negatives?\n",
    "\n",
    "- Based on your task (e.g., cancer detection), which type of error is more costly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 8 - Clustering (All Mandatory)\n",
    "\n",
    "In this assignment you will implement an unsupervised learning method, then you will test it with data sets of your choice. \n",
    "\n",
    "You must deliver the results in a jupyter notebook, combining the code, text, and images in a nice readable sequence.\n",
    "\n",
    "**Goal:** Implement the clustering algorithm called Bisecting k-Means.\n",
    "Bisecting k-Means [1] is a clustering algorithm that combines hierarchical clustering with k-Means. However, differently than the hierarchical clustering we saw in the lecture, it uses a divisive, top-down approach (instead of the agglomerative, bottom-up that we are used to). It consists on the steps described below:\n",
    "\n",
    "1. Start with a single cluster including all the observations in the data set.\n",
    "2. [Bisecting] Divide the largest cluster into two smaller sub-clusters using k-Means.\n",
    "3. Redo the bisecting step iter times and choose the best solution according to the Sum of Squared Errors (SSE).\n",
    "4. Repeat from Step 2 until you have k clusters.\n",
    "\n",
    "Implement the Bisecting k-Means algorithm in a function called bkmeans. It should take as input: (a) the data X to cluster, as a n × p matrix (n observations by p features); (b) the number k of clusters; and (c) the number iter of iterations for step 3. It should generate as output a n × 1 vector with the cluster indices for each of the n observations.\n",
    "Notes:\n",
    "1. You must implement K-Means yourself, from scratch.\n",
    "2. The requirements are strict. I will use standard test cases in order to test your solution by calling the function\n",
    "bkmeans as described.\n",
    "\n",
    "[1] M. Steinbach, G. Karypis, V. Kumar et al., “A comparison of document clustering techniques,” in\n",
    "KDD workshop on text mining, vol. 400, no. 1. Boston, 2000, pp. 525–526. [Online]. Available:\n",
    "http://glaros.dtc.umn.edu/gkhome/fetch/papers/docclusterKDDTMW00.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 9 - Dimensionality Reduction \n",
    "\n",
    "### Task 1 (mandatory)\n",
    "\n",
    "In this exercise you will visualize and explore the results of the previous exercise in a simple manner, using scatterplots.\n",
    "This will be a relatively open-ended task; you will choose three data sets and explore them with the new technique you built for yourself. \n",
    "\n",
    "These could be data sets you already used in previous assignments, or you could download some\n",
    "new data. The only restrictions are that (a) the data sets must be multidimensional (i.e., more than 4 features), (b) they must have labels, and (c) they must have at least 1000 data points.\n",
    "\n",
    "These are some examples of interesting places to obtain new data sets:\n",
    "\n",
    "* http://archive.ics.uci.edu/ml/index.php\n",
    "* https://www.openml.org/search?type=data\n",
    "* https://www.kaggle.com/datasets\n",
    "\n",
    "Be careful, however, with the size of the data set you choose. Python can get quite slow with too much data, and the scatterplots will also be very crowded, so go for smaller data sets this time.\n",
    "\n",
    "**Important**: Download the datasets and put them under the folder *datasets* so that we can run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Write your code here ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (non-mandatory) - Comparison of DR Techniques\n",
    "\n",
    "Generate a scatterplot matrix comparing the results of three DR techniques: PCA, MDS, and t-SNE, for each data set chosen in the previous exercise. \n",
    "The resulting visualization should be a 3 × 3 matrix where each cell is a scatterplot of a DR technique applied to a data set. \n",
    "Color the points by their target variables (i.e., class/labels) using a qualitative colormap.\n",
    "\n",
    "Then answer this shortly (in a couple of paragraphs): \n",
    "- In your opinion, which technique performed the best for each data set, regarding the separation of the classes? \n",
    "- How are the classes in the data sets separated? \n",
    "- Are some classes easier to separate than others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (non-mandatory): Comparison of Clustering Techniques\n",
    "\n",
    "Choose one of the DR techniques from the previous exercise and generate a similar scatterplot matrix to compare the results of Bisecting k-Means with classic k-Means and hierarchical clustering for each data set. \n",
    "The resulting visualization should be a 3 × 3 matrix where each cell is a scatterplot of the chosen DR technique applied to a data set, with the colors of the points showing the clusters using a qualitative colormap (see, e.g., https://matplotlib.org/tutorials/colors/colormaps.html).\n",
    "\n",
    "Then answer this shortly (in a couple of paragraphs): \n",
    "- In your opinion, which clustering technique performed the best for each data set? \n",
    "- How are the clusters in the data sets separated? \n",
    "- Are some clusters easier to separate than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
